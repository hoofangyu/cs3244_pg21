{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/train.pkl\").dropna()\n",
    "test = pd.read_pickle(\"data/test.pkl\").dropna()\n",
    "y_train = np.array(train['label'])\n",
    "y_test = np.array(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parent_tdidf_csr = vstack(train[\"parent_comment_tdidf\"])\n",
    "test_parent_tdidf_csr = vstack(test[\"parent_comment_tdidf\"])\n",
    "\n",
    "train_tdidf_csr = vstack(train[\"comment_tdidf_nn\"])\n",
    "test_tdidf_csr = vstack(test[\"comment_tdidf_nn\"])\n",
    "\n",
    "train_parent_bow_csr = vstack(train[\"parent_comment_bow\"])\n",
    "test_parent_bow_csr = vstack(test[\"parent_comment_bow\"])\n",
    "\n",
    "train_bow_csr = vstack(train[\"comment_bow\"])\n",
    "test_bow_csr = vstack(test[\"comment_bow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<161010x8160 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 855934 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tdidf_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = [\n",
    "       'comment_word_count','parent_comment_word_count',\n",
    "       'comment_token_count', 'parent_comment_token_count',\n",
    "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
    "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
    "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
    "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
    "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
    "       'comment_char_count', 'parent_comment_char_count',\n",
    "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
    "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
    "       'comment_number_count', 'parent_comment_number_count',\n",
    "       'weighted_parent_sentiment_score_neutral',\n",
    "       'weighted_parent_sentiment_score_positive',\n",
    "       'weighted_comment_sentiment_score_neutral',\n",
    "       'weighted_comment_sentiment_score_positive']\n",
    "bool_cols = ['weighted_parent_sentiment_score_neutral',\n",
    "             'weighted_parent_sentiment_score_positive',\n",
    "             'weighted_comment_sentiment_score_neutral',\n",
    "             'weighted_comment_sentiment_score_positive']\n",
    "\n",
    "for col in bool_cols: #need to convert bool type to integer\n",
    "    train[col] = train[col].astype(int)\n",
    "    test[col] = test[col].astype(int)\n",
    "X_train_gen_features = csr_matrix(train[list_of_features])\n",
    "\n",
    "X_test_gen_features = csr_matrix(test[list_of_features])\n",
    "x_train = hstack([X_train_gen_features,train_tdidf_csr]).toarray() #deep learning automates feature selection. from our supervised learning we have learnt that BoW adds no information given tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = train_tdidf_csr.toarray()\n",
    "x_test = hstack([X_test_gen_features,test_tdidf_csr]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18114/18114 [==============================] - 40s 2ms/step - loss: 0.6732 - accuracy: 0.5760 - val_loss: 0.7190 - val_accuracy: 0.5903\n",
      "Epoch 2/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.6242 - accuracy: 0.6512 - val_loss: 0.6136 - val_accuracy: 0.6599\n",
      "Epoch 3/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.6101 - accuracy: 0.6673 - val_loss: 0.6169 - val_accuracy: 0.6546\n",
      "Epoch 4/10\n",
      "18114/18114 [==============================] - 36s 2ms/step - loss: 0.5974 - accuracy: 0.6784 - val_loss: 0.6183 - val_accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.5907 - accuracy: 0.6854 - val_loss: 0.5950 - val_accuracy: 0.6765\n",
      "Epoch 6/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.5854 - accuracy: 0.6897 - val_loss: 0.6239 - val_accuracy: 0.6465\n",
      "Epoch 7/10\n",
      "18114/18114 [==============================] - 36s 2ms/step - loss: 0.5820 - accuracy: 0.6944 - val_loss: 0.6042 - val_accuracy: 0.6662\n",
      "Epoch 8/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.5775 - accuracy: 0.6972 - val_loss: 0.6164 - val_accuracy: 0.6555\n",
      "Epoch 9/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.5767 - accuracy: 0.6990 - val_loss: 0.6055 - val_accuracy: 0.6685\n",
      "Epoch 10/10\n",
      "18114/18114 [==============================] - 39s 2ms/step - loss: 0.5707 - accuracy: 0.7018 - val_loss: 0.5997 - val_accuracy: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ef45410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=8, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259/1259 [==============================] - 1s 864us/step\n",
      "AUC: 0.7419122793471202\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(x_test)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "print(f'AUC: {roc_auc_test}')\n",
    "#comment td-idf only AUC: 0.6628971516171749\n",
    "#gen features + comment td-idf AUC: 0.7419122793471202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yucai = test[[\"comment\"]]\n",
    "yucai_ans = test[[\"label\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
