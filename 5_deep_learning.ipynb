{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/train.pkl\").dropna()\n",
    "test = pd.read_pickle(\"data/test.pkl\").dropna()\n",
    "y_train = np.array(train['label'])\n",
    "y_test = np.array(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parent_tdidf_csr = vstack(train[\"parent_comment_tdidf\"])\n",
    "test_parent_tdidf_csr = vstack(test[\"parent_comment_tdidf\"])\n",
    "\n",
    "train_tdidf_csr = vstack(train[\"comment_tdidf_nn\"])\n",
    "test_tdidf_csr = vstack(test[\"comment_tdidf_nn\"])\n",
    "\n",
    "train_parent_bow_csr = vstack(train[\"parent_comment_bow\"])\n",
    "test_parent_bow_csr = vstack(test[\"parent_comment_bow\"])\n",
    "\n",
    "train_bow_csr = vstack(train[\"comment_bow\"])\n",
    "test_bow_csr = vstack(test[\"comment_bow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<161010x8160 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 855934 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tdidf_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_tdidf_csr.toarray()\n",
    "x_test = test_tdidf_csr.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = [\n",
    "       'comment_word_count','parent_comment_word_count',\n",
    "       'comment_token_count', 'parent_comment_token_count',\n",
    "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
    "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
    "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
    "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
    "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
    "       'comment_char_count', 'parent_comment_char_count',\n",
    "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
    "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
    "       'comment_number_count', 'parent_comment_number_count',\n",
    "       'weighted_parent_sentiment_score_neutral',\n",
    "       'weighted_parent_sentiment_score_positive',\n",
    "       'weighted_comment_sentiment_score_neutral',\n",
    "       'weighted_comment_sentiment_score_positive']\n",
    "bool_cols = ['weighted_parent_sentiment_score_neutral',\n",
    "             'weighted_parent_sentiment_score_positive',\n",
    "             'weighted_comment_sentiment_score_neutral',\n",
    "             'weighted_comment_sentiment_score_positive']\n",
    "\n",
    "for col in bool_cols: #need to convert bool type to integer\n",
    "    train[col] = train[col].astype(int)\n",
    "    test[col] = test[col].astype(int)\n",
    "X_train_gen_features = csr_matrix(train[list_of_features])\n",
    "\n",
    "X_test_gen_features = csr_matrix(test[list_of_features])\n",
    "X_train = hstack([X_train_gen_features,train_tdidf_csr,train_parent_tdidf_csr]) #deep learning automates feature selection. from our supervised learning we have learnt that BoW adds no information given tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.6166 - accuracy: 0.6524 - val_loss: 0.6002 - val_accuracy: 0.6678\n",
      "Epoch 2/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.5641 - accuracy: 0.7018 - val_loss: 0.6015 - val_accuracy: 0.6675\n",
      "Epoch 3/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.6315 - val_accuracy: 0.6640\n",
      "Epoch 4/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.4218 - accuracy: 0.8057 - val_loss: 0.7074 - val_accuracy: 0.6519\n",
      "Epoch 5/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.3442 - accuracy: 0.8471 - val_loss: 0.8011 - val_accuracy: 0.6441\n",
      "Epoch 6/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.2832 - accuracy: 0.8745 - val_loss: 0.9678 - val_accuracy: 0.6428\n",
      "Epoch 7/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.2393 - accuracy: 0.8946 - val_loss: 1.0992 - val_accuracy: 0.6373\n",
      "Epoch 8/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.2090 - accuracy: 0.9087 - val_loss: 1.2363 - val_accuracy: 0.6284\n",
      "Epoch 9/10\n",
      "18114/18114 [==============================] - 38s 2ms/step - loss: 0.1866 - accuracy: 0.9183 - val_loss: 1.3512 - val_accuracy: 0.6154\n",
      "Epoch 10/10\n",
      "18114/18114 [==============================] - 37s 2ms/step - loss: 0.1707 - accuracy: 0.9252 - val_loss: 1.5044 - val_accuracy: 0.6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3208ad7d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=8, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259/1259 [==============================] - 1s 968us/step\n",
      "AUC: 0.6628971516171749\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(x_test)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "print(f'AUC: {roc_auc_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
