{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.sparse import csr_matrix, vstack, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\").dropna()\n",
    "test = pd.read_pickle(\"test.pkl\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "encoded_train = pd.get_dummies(train, columns = ['weighted_parent_sentiment_score','weighted_comment_sentiment_score'], drop_first=True)\n",
    "encoded_test = pd.get_dummies(test, columns = ['weighted_parent_sentiment_score','weighted_comment_sentiment_score'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parent_tdidf_csr = vstack(encoded_train[\"parent_comment_tdidf\"])\n",
    "test_parent_tdidf_csr = vstack(encoded_test[\"parent_comment_tdidf\"])\n",
    "\n",
    "train_tdidf_csr = vstack(encoded_train[\"comment_tdidf\"])\n",
    "test_tdidf_csr = vstack(encoded_test[\"comment_tdidf\"])\n",
    "\n",
    "train_parent_bow_csr = vstack(encoded_train[\"parent_comment_bow\"])\n",
    "test_parent_bow_csr = vstack(encoded_test[\"parent_comment_bow\"])\n",
    "\n",
    "train_bow_csr = vstack(encoded_train[\"comment_bow\"])\n",
    "test_bow_csr = vstack(encoded_test[\"comment_bow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'author', 'subreddit', 'score', 'ups', 'downs', 'date',\n",
       "       'created_utc', 'parent_comment', 'comment_tokens',\n",
       "       'parent_comment_tokens', 'comment_score', 'parent_comment_score',\n",
       "       'comment_word_count', 'parent_comment_word_count',\n",
       "       'comment_token_count', 'parent_comment_token_count',\n",
       "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
       "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
       "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
       "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
       "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
       "       'comment_char_count', 'parent_comment_char_count',\n",
       "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
       "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
       "       'comment_number_count', 'parent_comment_number_count', 'comment_bow',\n",
       "       'parent_comment_bow', 'comment_tdidf', 'parent_comment_tdidf',\n",
       "       'comment_pos', 'parent_comment_pos', 'label',\n",
       "       'weighted_parent_sentiment_score_neutral',\n",
       "       'weighted_parent_sentiment_score_positive',\n",
       "       'weighted_comment_sentiment_score_neutral',\n",
       "       'weighted_comment_sentiment_score_positive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = ['score','ups','downs',\n",
    "       'comment_word_count','parent_comment_word_count',\n",
    "       'comment_token_count', 'parent_comment_token_count',\n",
    "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
    "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
    "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
    "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
    "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
    "       'comment_char_count', 'parent_comment_char_count',\n",
    "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
    "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
    "       'comment_number_count', 'parent_comment_number_count',\n",
    "       'weighted_parent_sentiment_score_neutral',\n",
    "       'weighted_parent_sentiment_score_positive',\n",
    "       'weighted_comment_sentiment_score_neutral',\n",
    "       'weighted_comment_sentiment_score_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gen_features = csr_matrix(encoded_train[list_of_features])\n",
    "y_train_LR = encoded_train['label']\n",
    "\n",
    "X_test_gen_features = csr_matrix(encoded_test[list_of_features])\n",
    "y_test_LR = encoded_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: General Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = X_train_gen_features\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.5491668979599857\n",
      "Standard Deviation of Accuracy: 0.0012069456637832066\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2: Comment BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = train_bow_csr\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6559993561709694\n",
      "Standard Deviation of Accuracy: 0.002844977393892126\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 3: Comment TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = train_tdidf_csr\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6562290582042054\n",
      "Standard Deviation of Accuracy: 0.0017472335992932341\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4: General Features + BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_bow_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6607794658843569\n",
      "Standard Deviation of Accuracy: 0.002248445257500324\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 5: General Features + TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6610712542666517\n",
      "Standard Deviation of Accuracy: 0.0020377135405951733\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 6: Gen Features + Comment TDIDF + Parent TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_tdidf_csr,train_parent_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.654434994761244\n",
      "Standard Deviation of Accuracy: 0.003712193442411324\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 7: Gen + Parent TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_parent_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.5686163857151365\n",
      "Standard Deviation of Accuracy: 0.001434463462199886\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter = 1000)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
