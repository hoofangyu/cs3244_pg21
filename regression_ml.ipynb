{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\").dropna()\n",
    "test = pd.read_pickle(\"test.pkl\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "encoded_train = pd.get_dummies(train, columns = ['weighted_parent_sentiment_score','weighted_comment_sentiment_score'], drop_first=True)\n",
    "encoded_test = pd.get_dummies(test, columns = ['weighted_parent_sentiment_score','weighted_comment_sentiment_score'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parent_tdidf_csr = vstack(encoded_train[\"parent_comment_tdidf\"])\n",
    "test_parent_tdidf_csr = vstack(encoded_test[\"parent_comment_tdidf\"])\n",
    "\n",
    "train_tdidf_csr = vstack(encoded_train[\"comment_tdidf\"])\n",
    "test_tdidf_csr = vstack(encoded_test[\"comment_tdidf\"])\n",
    "\n",
    "train_parent_bow_csr = vstack(encoded_train[\"parent_comment_bow\"])\n",
    "test_parent_bow_csr = vstack(encoded_test[\"parent_comment_bow\"])\n",
    "\n",
    "train_bow_csr = vstack(encoded_train[\"comment_bow\"])\n",
    "test_bow_csr = vstack(encoded_test[\"comment_bow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'author', 'subreddit', 'score', 'ups', 'downs', 'date',\n",
       "       'created_utc', 'parent_comment', 'comment_tokens',\n",
       "       'parent_comment_tokens', 'comment_score', 'parent_comment_score',\n",
       "       'comment_word_count', 'parent_comment_word_count',\n",
       "       'comment_token_count', 'parent_comment_token_count',\n",
       "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
       "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
       "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
       "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
       "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
       "       'comment_char_count', 'parent_comment_char_count',\n",
       "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
       "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
       "       'comment_number_count', 'parent_comment_number_count', 'comment_bow',\n",
       "       'parent_comment_bow', 'comment_tdidf', 'parent_comment_tdidf',\n",
       "       'comment_pos', 'parent_comment_pos', 'label',\n",
       "       'weighted_parent_sentiment_score_neutral',\n",
       "       'weighted_parent_sentiment_score_positive',\n",
       "       'weighted_comment_sentiment_score_neutral',\n",
       "       'weighted_comment_sentiment_score_positive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = ['score','ups','downs',\n",
    "       'comment_word_count','parent_comment_word_count',\n",
    "       'comment_token_count', 'parent_comment_token_count',\n",
    "       'comment_unique_word_count', 'parent_comment_unique_word_count',\n",
    "       'comment_unique_token_count', 'parent_comment_unique_token_count',\n",
    "       'comment_stopword_count', 'parent_comment_stopword_count',\n",
    "       'comment_mean_word_length', 'parent_comment_mean_word_length',\n",
    "       'comment_mean_token_length', 'parent_comment_mean_token_length',\n",
    "       'comment_char_count', 'parent_comment_char_count',\n",
    "       'comment_punctuation_count', 'parent_comment_punctuation_count',\n",
    "       'comment_hashtag_count', 'parent_comment_hashtag_count',\n",
    "       'comment_number_count', 'parent_comment_number_count',\n",
    "       'weighted_parent_sentiment_score_neutral',\n",
    "       'weighted_parent_sentiment_score_positive',\n",
    "       'weighted_comment_sentiment_score_neutral',\n",
    "       'weighted_comment_sentiment_score_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gen_features = csr_matrix(encoded_train[list_of_features])\n",
    "y_train_LR = encoded_train['label']\n",
    "\n",
    "X_test_gen_features = csr_matrix(encoded_test[list_of_features])\n",
    "y_test_LR = encoded_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: General Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = X_train_gen_features\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.549073778456603\n",
      "Standard Deviation of Accuracy: 0.0011866425387839022\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2: Comment BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = train_bow_csr\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6559869405583454\n",
      "Standard Deviation of Accuracy: 0.002837919243242117\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 3: Comment TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Specific Prep\n",
    "X_train_LR = train_tdidf_csr\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6562352661068654\n",
      "Standard Deviation of Accuracy: 0.0017712936494375434\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4: General Features + BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_bow_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6607484256002715\n",
      "Standard Deviation of Accuracy: 0.0023205634651901974\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 5: General Features + TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6611209176806286\n",
      "Standard Deviation of Accuracy: 0.0020015926105550713\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 6: Gen Features + Comment TDIDF + Parent TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_tdidf_csr,train_parent_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6544101625725147\n",
      "Standard Deviation of Accuracy: 0.0036873570540180743\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 7: Gen + Parent TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_parent_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.568635008845028\n",
      "Standard Deviation of Accuracy: 0.0013539634505594297\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_scores = []\n",
    "for train_index, val_index in kf.split(X_train_LR): \n",
    "    X_train, X_val = X_train_LR[train_index], X_train_LR[val_index]\n",
    "    y_train, y_val = y_train_LR.iloc[train_index,], y_train_LR.iloc[val_index,]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and store it in the list\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cross_val_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(cross_val_scores) / k\n",
    "std_accuracy = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning with Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = hstack([X_train_gen_features,train_tdidf_csr])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_LR = scaler.fit_transform(X_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "    'max_iter': [100,200,300]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
